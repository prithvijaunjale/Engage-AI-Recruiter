{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "engage_audio_model_cnn_lstm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "14yNFlO3_FErfysu7xQDqHe_1hjtAfU3q",
      "authorship_tag": "ABX9TyOzHOr+jhjaoO6ewiUO7Xex",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prithvijaunjale/Engage-AI-Recruiter/blob/master/engage_audio_model_cnn_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIwge5xJhrfj",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pz0bVYJq5QyE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "6072e127-9f13-40b6-8fc5-6998f313a656"
      },
      "source": [
        "! pip install torchaudio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchaudio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/0a/40e53c686c2af65b2a4e818d11d9b76fa79178440caf99f3ceb2a32c3b04/torchaudio-0.5.1-cp36-cp36m-manylinux1_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.5.1 in /usr/local/lib/python3.6/dist-packages (from torchaudio) (1.5.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1->torchaudio) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1->torchaudio) (0.16.0)\n",
            "Installing collected packages: torchaudio\n",
            "Successfully installed torchaudio-0.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6iOcfhZnpJk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import os\n",
        "import io\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image, ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "from collections import OrderedDict\n",
        "\n",
        "import shutil\n",
        "from zipfile import ZipFile\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, SubsetRandomSampler\n",
        "from torch.utils.data import Dataset\n",
        "from torch import optim\n",
        "\n",
        "import librosa\n",
        "from librosa.display import specshow\n",
        "import torchaudio\n",
        "\n",
        "project_dir = 'drive/My Drive/projects/engage_ai_recruiter/'\n",
        "models_dir = 'drive/My Drive/projects/engage_ai_recruiter/models/audio/'\n",
        "data_dir = 'drive/My Drive/projects/engage_ai_recruiter/data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ0f5oDGc3kx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cp drive/My\\ Drive/projects/engage_ai_recruiter/data/all_wav.zip all_wav.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFsFCa2ndafd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shutil.unpack_archive('all_wav.zip', '', 'zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eCXak2POJpb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "90b2ed92-d2bf-4cac-9c3e-b98ca5f02a13"
      },
      "source": [
        "all_wav = os.listdir('all_wav')\n",
        "len(all_wav)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OodbnndHl--L",
        "colab_type": "text"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSG1Wvg7nhqF",
        "colab_type": "text"
      },
      "source": [
        "## DALI (NVIDIA Data Loading Library)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhRCgWpenlP2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "99f6c70b-a2cb-4e95-85f2-c1a54d6f2d5a"
      },
      "source": [
        "! nvcc --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hDH9ryUnqAF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "71090421-72ca-42e8-a712-3e27e24eb793"
      },
      "source": [
        "! pip3 install --extra-index-url https://developer.download.nvidia.com/compute/redist nvidia-dali-cuda100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://developer.download.nvidia.com/compute/redist\n",
            "Collecting nvidia-dali-cuda100\n",
            "\u001b[?25l  Downloading https://developer.download.nvidia.com/compute/redist/nvidia-dali-cuda100/nvidia_dali_cuda100-0.23.0-1396139-cp36-cp36m-manylinux1_x86_64.whl (264.6MB)\n",
            "\u001b[K     |████████████████████████████████| 264.6MB 55kB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from nvidia-dali-cuda100) (0.16.0)\n",
            "Installing collected packages: nvidia-dali-cuda100\n",
            "Successfully installed nvidia-dali-cuda100-0.23.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jifc5Po3nqJN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nvidia.dali.ops as ops\n",
        "import nvidia.dali.types as types\n",
        "from nvidia.dali.pipeline import Pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a2L57nB7JkP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_melspecgram(y):\n",
        "    mel_specgram = torchaudio.transforms.MelSpectrogram(n_fft=1024,\n",
        "                                                        hop_length=256,\n",
        "                                                        n_mels=40,\n",
        "                                                        sample_rate=16000)(y_mono)\n",
        "    mel_specgram = librosa.power_to_db(mel_specgram, ref=np.max)    \n",
        "\n",
        "    specshow(mel_specgram, fmax=8000)\n",
        "    buf = io.BytesIO()\n",
        "    plt.savefig(buf, format='png', bbox_inches='tight')\n",
        "    buf.seek(0)\n",
        "    return buf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAxXgekfnqME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ExternalInputIterator(object):\n",
        "    def __init__(self, batch_size, csv_file, root_dir, indices):\n",
        "        self.root_dir = root_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.wav_df = pd.read_csv(csv_file)\n",
        "        self.wav_df = self.wav_df.iloc[indices, :]\n",
        "\n",
        "    def __iter__(self):\n",
        "        self.i = 0\n",
        "        self.n = len(self.wav_df)\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        b_wavs = []\n",
        "        b_labels = []\n",
        "        for _ in range(self.batch_size):\n",
        "            wav = os.path.join(self.root_dir, self.wav_df.iloc[self.i, 0])\n",
        "            y, sr = torchaudio.load(wav)\n",
        "            y = y.squeeze(0).numpy()\n",
        "            y = y[:(int(16000 * 15))]\n",
        "            b_wavs.append(y)\n",
        "\n",
        "            labels = self.wav_df.iloc[self.i, 1:].values.astype(np.float32)\n",
        "            b_labels.append(labels)\n",
        "\n",
        "            self.i = (self.i + 1) % self.n\n",
        "        return (b_wavs, b_labels)\n",
        "\n",
        "    @property\n",
        "    def size(self,):\n",
        "        return len(self.wav_df)\n",
        "\n",
        "    next = __next__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8wnzuAUiZ2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MelSpectrogramPipeline(Pipeline):\n",
        "    def __init__(self, \n",
        "                 external_data,\n",
        "                 device, \n",
        "                 batch_size, \n",
        "                 specgram_dict, \n",
        "                 num_threads=1, \n",
        "                 device_id=0):\n",
        "        super(MelSpectrogramPipeline, self).__init__(batch_size, num_threads, device_id)\n",
        "\n",
        "        self.device = device\n",
        "        self.data_iterator = iter(external_data)\n",
        "        self.specgram_dict = specgram_dict\n",
        "        \n",
        "        # input\n",
        "        self.input_wav = ops.ExternalSource()\n",
        "        self.input_label = ops.ExternalSource()\n",
        "\n",
        "        # audio\n",
        "        self.spectrogram = ops.Spectrogram(device=self.device,\n",
        "                                           nfft=self.specgram_dict['n_fft'],\n",
        "                                           window_length=self.specgram_dict['n_fft'],\n",
        "                                           window_step=self.specgram_dict['hop_length'])\n",
        "        self.mel_fbank = ops.MelFilterBank(device=self.device,\n",
        "                                           sample_rate=self.specgram_dict['sr'],\n",
        "                                           nfilter = self.specgram_dict['n_mels'],\n",
        "                                           freq_high = self.specgram_dict['f_max'])\n",
        "        self.dB = ops.ToDecibels(device=self.device,\n",
        "                                 multiplier = 10.0,\n",
        "                                 cutoff_db = -80)\n",
        "        \n",
        "        # image\n",
        "        self.decode = ops.ImageDecoder(device=self.device)\n",
        "        self.res = ops.Resize(device=self.device, resize_x=224, resize_y=224)\n",
        "        self.norm = ops.CropMirrorNormalize(device = self.device,\n",
        "                                            mean=[0.485, 0.456, 0.406], \n",
        "                                            std=[0.229, 0.224, 0.225])\n",
        "        \n",
        "    def define_graph(self):\n",
        "        # audio transforms\n",
        "        self.y = self.input_wav()\n",
        "        self.labels = self.input_label()\n",
        "        self.y = self.y.gpu() if self.device == 'gpu' else self.y\n",
        "        specgram = self.spectrogram(self.y)\n",
        "        mel_specgram = self.mel_fbank(specgram)\n",
        "        mel_specgram_db = self.dB(mel_specgram)\n",
        "        return (mel_specgram_db, self.labels)\n",
        "\n",
        "    def iter_setup(self):\n",
        "        y, labels = self.data_iterator.next()\n",
        "        self.feed_input(self.y, y)\n",
        "        self.feed_input(self.labels, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Znm3GLVpAE0x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating data indices for training and validation splits\n",
        "wav_df = pd.read_csv(data_dir + 'WAV_OCEANI.csv')\n",
        "\n",
        "validation_split = 0.2\n",
        "shuffle_dataset = True\n",
        "random_seed = 42\n",
        "\n",
        "dataset_size = len(wav_df)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "if shuffle_dataset :\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "train_indices, val_indices = indices[split:], indices[:split]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3IPqHLjnqPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_eii = ExternalInputIterator(batch_size=32, \n",
        "                            csv_file=data_dir + 'WAV_OCEANI.csv', \n",
        "                            root_dir='all_wav',\n",
        "                            indices=train_indices)\n",
        "\n",
        "val_eii = ExternalInputIterator(batch_size=32, \n",
        "                            csv_file=data_dir + 'WAV_OCEANI.csv', \n",
        "                            root_dir='all_wav',\n",
        "                            indices=val_indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdhdCKtR3g13",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "a8e9e957-db54-4ab6-e1ab-6f56e6f48aaa"
      },
      "source": [
        "# build pipeline, initialize iterator\n",
        "\n",
        "from nvidia.dali.plugin.pytorch import DALIGenericIterator\n",
        "\n",
        "specgram_dict = {'n_fft': 1024,\n",
        "                 'hop_length': 256,\n",
        "                 'n_mels': 40,\n",
        "                 'sr': 16000,\n",
        "                 'f_max': 8000,\n",
        "                 'duration': 15}\n",
        "\n",
        "train_pipe = MelSpectrogramPipeline(external_data=train_eii, \n",
        "                                    device='gpu',\n",
        "                                    specgram_dict=specgram_dict,\n",
        "                                    batch_size=32,\n",
        "                                    device_id=0)\n",
        "train_pipe.build()\n",
        "\n",
        "val_pipe = MelSpectrogramPipeline(external_data=train_eii,\n",
        "                                  device='gpu',\n",
        "                                  specgram_dict=specgram_dict, \n",
        "                                  batch_size=32, \n",
        "                                  device_id=0)\n",
        "val_pipe.build()\n",
        "\n",
        "train_iterator = DALIGenericIterator(train_pipe, \n",
        "                                     ['mel_specgram_db', 'labels'], \n",
        "                                     size=train_eii.size)\n",
        "val_iterator = DALIGenericIterator(val_pipe, \n",
        "                                   ['mel_specgram_db', 'labels'], \n",
        "                                   size=val_eii.size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nvidia/dali/plugin/base_iterator.py:124: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.\n",
            "  _iterator_deprecation_warning()\n",
            "/usr/local/lib/python3.6/dist-packages/nvidia/dali/plugin/base_iterator.py:124: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.\n",
            "  _iterator_deprecation_warning()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJqAfEpqOyYC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "824d7c83-b836-4d18-c3f3-e943ee6e9766"
      },
      "source": [
        "for item in train_iterator:\n",
        "    print(item[0]['mel_specgram_db'].shape)\n",
        "    break\n",
        "train_iterator.reset()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 40, 938])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_GpAo-9Sy2k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "42b95cb0-eb19-4c3c-dd57-af99277f9fc8"
      },
      "source": [
        "# set lengths of the iterators early on, \n",
        "# cause calculating the length every time makes a full run through the iterator\n",
        "# which might consume the gpu memory\n",
        "\n",
        "train_iterator.reset()\n",
        "val_iterator.reset()\n",
        "\n",
        "len_train_iterator = len(list(train_iterator))\n",
        "len_val_iterator = len(list(val_iterator))\n",
        "\n",
        "print(len_train_iterator, len_val_iterator)\n",
        "\n",
        "# reset iterators before the start of every epoch\n",
        "train_iterator.reset()\n",
        "val_iterator.reset()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...\n",
            "WARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "199 50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9YQ7c5sjacU",
        "colab_type": "text"
      },
      "source": [
        "# CNN - LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wzDJCJ2QjgZ3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a7adbd09-4e14-4be6-9918-d19beeb55d6a"
      },
      "source": [
        "device = torch.device('cuda')\n",
        "print(torch.cuda.get_device_name())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoyKHb9T37aU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "b59f33ea-3fbd-4a12-aebd-6ea1160877c2"
      },
      "source": [
        "\"\"\"\n",
        "input dimensions\n",
        "[batch_size, 1, 957, 40]\n",
        "975 - timesteps (in milliseconds | 15 seconds)\n",
        "40 - embeddings (mel freq bins | n_mels)\n",
        "\n",
        "conv1 out - [-1, 32, 975, 1]\n",
        "pool1 out - [-1, 32, 487, 1]\n",
        "\n",
        "conv2 out - [-1, 64, 487, 1]\n",
        "pool2 out - [-1, 64, 243, 1]\n",
        "\n",
        "conv3 out - [-1, 128, 243, 1]\n",
        "pool3 out - [-1, 128, 121, 1]\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'\\ninput dimensions\\n[batch_size, 1, 957, 40]\\n975 - timesteps (in milliseconds | 15 seconds)\\n40 - embeddings (mel freq bins | n_mels)\\n\\nconv1 out - [-1, 32, 975, 1]\\npool1 out - [-1, 32, 487, 1]\\n\\nconv2 out - [-1, 64, 487, 1]\\npool2 out - [-1, 64, 243, 1]\\n\\nconv3 out - [-1, 128, 243, 1]\\npool3 out - [-1, 128, 121, 1]\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wRiZqZbAjgZ9",
        "colab": {}
      },
      "source": [
        "class CnnLstmModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, \n",
        "                               out_channels=32, \n",
        "                               kernel_size=(1, 40))\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, \n",
        "                               out_channels=64, \n",
        "                               kernel_size=(3, 1))\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, \n",
        "                               out_channels=128, \n",
        "                               kernel_size=(3, 1))\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=(2, 1), stride=2)\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=128, \n",
        "                            hidden_size=64, \n",
        "                            batch_first=True,\n",
        "                            bidirectional=True)\n",
        "        \n",
        "        self.fc1 = nn.Linear(128, 16)\n",
        "        self.o_output = nn.Linear(16, 1)\n",
        "        self.c_output = nn.Linear(16, 1)\n",
        "        self.e_output = nn.Linear(16, 1)\n",
        "        self.a_output = nn.Linear(16, 1)\n",
        "        self.n_output = nn.Linear(16, 1)\n",
        "        self.i_output = nn.Linear(16, 1)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.25)\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.maxpool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.maxpool(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        pool_out = self.maxpool(x)\n",
        "\n",
        "        lstm_inp = pool_out.squeeze().permute(0, 2, 1)\n",
        "        lstm_out, (h_n, c_n) = self.lstm(lstm_inp)\n",
        "        x = F.relu(lstm_out[:, -1, :])\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        o_out = F.sigmoid(self.o_output(x))\n",
        "        c_out = F.sigmoid(self.c_output(x))\n",
        "        e_out = F.sigmoid(self.e_output(x))\n",
        "        a_out = F.sigmoid(self.a_output(x))\n",
        "        n_out = F.sigmoid(self.n_output(x))\n",
        "        i_out = F.sigmoid(self.i_output(x))\n",
        "\n",
        "        return [o_out, c_out, e_out, a_out, n_out, i_out]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uO3m0jyujgZ_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "1435d1a8-3169-4cab-9709-326d65985bf2"
      },
      "source": [
        "model = CnnLstmModel()\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CnnLstmModel(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(1, 40), stride=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 1), stride=(1, 1))\n",
              "  (conv3): Conv2d(64, 128, kernel_size=(3, 1), stride=(1, 1))\n",
              "  (maxpool): MaxPool2d(kernel_size=(2, 1), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (lstm): LSTM(128, 64, batch_first=True, bidirectional=True)\n",
              "  (fc1): Linear(in_features=128, out_features=16, bias=True)\n",
              "  (o_output): Linear(in_features=16, out_features=1, bias=True)\n",
              "  (c_output): Linear(in_features=16, out_features=1, bias=True)\n",
              "  (e_output): Linear(in_features=16, out_features=1, bias=True)\n",
              "  (a_output): Linear(in_features=16, out_features=1, bias=True)\n",
              "  (n_output): Linear(in_features=16, out_features=1, bias=True)\n",
              "  (i_output): Linear(in_features=16, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.25, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ghnvnf7vjgaC",
        "colab": {}
      },
      "source": [
        "# get out shape\n",
        "# sample = next(iter(train_iterator))\n",
        "# b_input = sample[0]['mel_specgram_db'].unsqueeze(1).to(device)\n",
        "# b_input = b_input.permute(0, 1, 3, 2)\n",
        "# print(b_input.shape)\n",
        "# lstm_out, (h_n, c_n) = model.forward(b_input)\n",
        "# h_n.shape\n",
        "# out = out.squeeze().permute(0, 2, 1)\n",
        "# out.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QNYh3cjdjgaE",
        "colab": {}
      },
      "source": [
        "mse_criterion = nn.MSELoss()\n",
        "mae_criterion = nn.L1Loss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "epochs = 10\n",
        "save_best_only = True\n",
        "early_stopping_limit = epochs\n",
        "model_name = 'cnn_melspecgram_mse'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZFppB43ajgaF",
        "colab": {}
      },
      "source": [
        "training_losses, val_losses = [], []\n",
        "prev_val_loss, min_val_loss = 0, 9999\n",
        "early_stopping_cnt = 0\n",
        "train_iterator.reset()\n",
        "val_iterator.reset()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Training\n",
        "    train_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for batch in tqdm(train_iterator, total=len_train_iterator, desc='Epoch ' + str(epoch)):\n",
        "        b_input, b_labels = batch[0]['mel_specgram_db'], batch[0]['labels']\n",
        "        b_input, b_labels = b_input.unsqueeze(1).to(device), b_labels.to(device)\n",
        "        b_input = b_input.permute(0, 1, 3, 2)\n",
        "\n",
        "        # clear accumulated gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward pass\n",
        "        logits = model.forward(b_input)\n",
        "\n",
        "        # calc loss\n",
        "        mse_loss_sum, mae_loss_sum = 0, 0\n",
        "\n",
        "        for idx, logit in enumerate(logits):\n",
        "            temp_mse = mse_criterion(logit, b_labels[idx])\n",
        "            mse_loss_sum += temp_mse\n",
        "\n",
        "            temp_mae = mae_criterion(logit, b_labels[idx])\n",
        "            mae_loss_sum += temp_mae\n",
        "\n",
        "        mse_loss_avg = mse_loss_sum / len(logits)\n",
        "        mae_loss_avg = mae_loss_sum / len(logits)\n",
        "\n",
        "        mse_mae_avg = (mse_loss_avg + mae_loss_avg) / 2\n",
        "        train_loss += mse_mae_avg.item()\n",
        "\n",
        "        # backward pass\n",
        "        mse_mae_avg.backward()\n",
        "\n",
        "        # update weights\n",
        "        optimizer.step()\n",
        "    \n",
        "    avg_train_loss = train_loss/len_train_iterator\n",
        "    training_losses.append(avg_train_loss)\n",
        "    print('Avg Training MSE_MAE:', avg_train_loss)\n",
        "\n",
        "    # Validation\n",
        "    val_loss = 0\n",
        "    pred, true = [], []\n",
        "    val_o_loss, val_c_loss, val_e_loss, val_a_loss, val_n_loss, val_i_loss = 0, 0, 0, 0, 0, 0\n",
        "\n",
        "    model.eval()\n",
        "    for batch in val_iterator:\n",
        "        b_input, b_labels = batch[0]['mel_specgram_db'], batch[0]['labels']\n",
        "        b_input, b_labels = b_input.unsqueeze(1).to(device), b_labels.to(device)\n",
        "        b_input = b_input.permute(0, 1, 3, 2)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model.forward(b_input)\n",
        "\n",
        "            # calc loss\n",
        "            mse_loss_sum, mae_loss_sum = 0, 0\n",
        "\n",
        "            for idx, logit in enumerate(logits):\n",
        "                temp_mse = mse_criterion(logit, b_labels[idx])\n",
        "                mse_loss_sum += temp_mse\n",
        "\n",
        "                temp_mae = mae_criterion(logit, b_labels[idx])\n",
        "                mae_loss_sum += temp_mae\n",
        "\n",
        "            mse_loss_avg = mse_loss_sum / len(logits)\n",
        "            mae_loss_avg = mae_loss_sum / len(logits)\n",
        "\n",
        "            mse_mae_avg = (mse_loss_avg + mae_loss_avg) / 2\n",
        "\n",
        "            val_loss += mse_mae_avg.item()\n",
        "            # val_o_loss += o_loss.item()\n",
        "            # val_c_loss += c_loss.item()\n",
        "            # val_e_loss += e_loss.item()\n",
        "            # val_a_loss += a_loss.item()\n",
        "            # val_n_loss += n_loss.item()\n",
        "            # val_i_loss += i_loss.item()\n",
        "\n",
        "            logits_numpy = [logit.cpu().numpy() for logit in logits]\n",
        "            labels = b_labels.cpu().numpy()\n",
        "\n",
        "            for logits in logits_numpy:\n",
        "                pred.extend(logits)\n",
        "            for label in labels:\n",
        "                true.extend(label)\n",
        "\n",
        "    avg_val_loss = val_loss / len_val_iterator\n",
        "    val_losses.append(avg_val_loss)\n",
        "    # print('\\nO Validation MSE_MAE:', val_o_loss/len_val_iterator)\n",
        "    # print('C Validation MSE_MAE:', val_c_loss/len_val_iterator)\n",
        "    # print('E Validation MSE_MAE:', val_e_loss/len_val_iterator)\n",
        "    # print('A Validation MSE_MAE:', val_a_loss/len_val_iterator)\n",
        "    # print('N Validation MSE_MAE:', val_n_loss/len_val_iterator)\n",
        "    # print('I Validation MSE_MAE:', val_i_loss/len_val_iterator)\n",
        "\n",
        "    print('Avg Validation MSE_MSE:', avg_val_loss)\n",
        "    print('Validation MAE:', mean_absolute_error(true, pred))\n",
        "    # reset iterator after every epoch\n",
        "    train_iterator.reset()\n",
        "    val_iterator.reset()\n",
        "\n",
        "    if save_best_only and avg_val_loss < min_val_loss: \n",
        "        if not os.path.exists(models_dir + model_name):\n",
        "            os.makedirs(models_dir + model_name)\n",
        "        torch.save(model.state_dict(), os.path.join(models_dir, model_name, model_name + '.pt'))\n",
        "        print(f'--- Model Saved. Val loss: {min_val_loss} -> {avg_val_loss}')\n",
        "        min_val_loss = avg_val_loss\n",
        "        early_stopping_cnt = 0\n",
        "\n",
        "    early_stopping_cnt += 1\n",
        "    if early_stopping_cnt == early_stopping_limit:\n",
        "        print('\\n--- Stopped Early.')\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRoKm0SPSQpB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}